{
  "pages": [
    {
      "title": "Progress Tracker",
      "text": "2018 March 08",
      "tags": "",
      "url": "https://thestrawh8.netlify.com/stories/progress.html"
    },
    {
      "title": "Understanding the Max Plank's UP project.",
      "text": "In this I would like to share the working of UP.\nWhen trying to read the paper I couldn't didn't get the things clearly but it is the same SMPLify concept which has been also taken up in many of Max Plank's design which is palying major role in all of these.\n \n\n They have designed a PCA model of complete bosy and giving the image as an input to the system they try to estimate the pose of the human in the image with a bound which is not explicitly mentioned but we find good results when the image satisfies the condition that the person covers below 500 pixels in the image. So using deeplab model they try to estimate the pose and also the keypoints either 14/91 based on the models you choose. This pose content is then used to estiamte the camera parameters and keypoints to optimize the model based on the keypoints skeleton using the SMPLify and again as usual the same reprojection error minimization concept is used to estimate the model. Thus we finally obtain a model shape which is similar to one's in the image. It has been mentioned in the paper that it almost works in 30fps which is really amazing.\nBelow we can see original and the estimated model's image.",
      "tags": "Research",
      "url": "https://thestrawh8.netlify.com/posts/understanding-the-max-planks-up-project.html"
    },
    {
      "title": "Patrick Huber's EOS and its working.",
      "text": "Patrick's model is the only to truluy mention which has made the complete end to end process pipeline as opensource since this reconstruction of human faces has some market value as it has a capability to attract a good amount of people that might be the reason for less exposure of the code. Okay coming to partick's work it based on surrey model (University of Surrey).\n\nIt can be said it is most possible simplest pipeline for 2D-3D reconstruction of human face by simplest I mean relatively because it uses a linear techniques in order to estimate. So basically using some landmark detector we try to detect the landmarks where patrick's implementation supports 68 ones I personally prefer the ibug one. Using the landmark file we try to estiamte the camera parameters and try to minimize the error between the 2D landmarks and the projected 3D landmarks usually we come across this technique in Sfm technique and also other 3D reconstruciton pipeline because it is the heart of reconstruction. Using the camera parameters and the surrey's PCA model and the landmark points they to estiamte the shape parameters and project the image onto the 3D face. Patrick is still continuing his work by making the implementaion compatible with Basel Face Model & also trying to optimiza the parameters using Non linear implementations like Cerses Solver.\nThe sample output will look like this",
      "tags": "Research",
      "url": "https://thestrawh8.netlify.com/posts/playing-with-patrick-hubers-eos-and-explaining-how-it-is-not-going-to-support-our-pipeline.html"
    },
    {
      "title": "Conversion of a video sequence to a Avatar's GIF/video sequence.",
      "text": "Recently a lot research has been taking place in the region of combination of Computer Graphics & Computer Vision areas and the standards are being expected to raise after apple's introduction of Iphone X which have cutdown a lot of efforts in coverting the 2D-3D mapping using its front camera which seems to project a huge number of IR rays to estimate the geometry of the human face but it is really hard for a normal person to afford such high costs so I myself being an Indian and want to make it available to the normal families to experience such high end technolgies which would build more passion towards learning have taken up this project as one of my most import project and am planning to work in parallel along with mathematical visualization of Machine Learning and its advancements. \n\n\n\nI would like to keep this as a log which will help me remember the flow of work which I have planned to implement this work. It has really taken a lot of time since I am all by myself if having any advisor would have made work a bit more easier since with their experience I probably would have been directed to this point, Since I first became aware of this 3D Face Reconstruction technology based on the works of Prof.Ira Kemelmacher - UW CSE, I was first trying to understand the Shape from Shading, Structure from Motion techniques since I being from an EE background never had a chance to take up an Computer Graphics course even though I had taken up Computer Vision course in my final semester I wasn't much interested at that point of time since my drive was always towards the mathematical concepts that have been entangled either be it Machine Learning / Computer Vision / Medical Imaging or anything i was just addicted to the understanding of concepts on my own since I felt I would lose the kick/joy which I would gain during learning it after reading pages after pages sadly I was into that buble I kept reading papers after papers even till today I am doing the same but I realisez it is the time to take some action instead of aiming for one big ball, I should first pick up the lego pieces and try to join once after the other. Sorry I have gone completely out of the topic coming back, Every time I try to think about this problem how to make the 2D-3D interaction in a way with lesser complexity and higher accessibility always diffrent combinations of pipelines pop up in my mind instead I have decided I should implement one at first then it would make me clear during the implementation process how to permute the blocks in the pipeleine.",
      "tags": "Research",
      "url": "https://thestrawh8.netlify.com/posts/conversion-of-a-video-sequence-to-a-avatars-gifvideo-sequence.html"
    },
    {
      "title": "The Speed of Asymptotic Sequential Learning.",
      "text": "Review of Journal of Economics Paper by Omer Tamuz's Group\n\nIn brief this paper tries to focus on the convergance rate and its dependencies on actions and signals. They try to prove that the convergence occurs quickly with respect signals external observations rather than actions using a two state stochastic process. Taking the case of Gaussian distribution as the signal distribution they prove that the convergence with respect to actions occurs by \\(\\sqrt{\\log t}\\) times faster. They also discuss the definitivity of the convergence. \nThey were also emphasizing on the sublinerity of the actions influence. Sublinearity means \\(\\lim\\limits_{n \\to \\infty} \\frac{x_n}{n}\\).",
      "tags": "Economics,Learning Theory,mathjax",
      "url": "https://thestrawh8.netlify.com/posts/the-speed-of-sequential-asymptotic.html"
    },
    {
      "title": "Twitter Bird using DQN - a review",
      "text": "",
      "tags": "",
      "url": "https://thestrawh8.netlify.com/posts/twitter-bird-using-dqn-a-review.html"
    },
    {
      "title": "Programming Solutions Collection",
      "text": "Merge Two Binary Trees\nclass Solution {\npublic:\n    TreeNode* mergeTrees(TreeNode *t1,TreeNode *t2) {\n\n        if(t1==NULL && t2==NULL){\n            return NULL;\n        }\n        else{\n            if(t1==NULL){\n                t1 = t2;\n            }\n            else if(t1 !=NULL && t2 !=NULL){\n                t1->val = t1->val + t2->val;\n                t1->left = mergeTrees(t1->left,t2->left);\n                t1->right = mergeTrees(t1->right,t2->right);\n            }\n            return t1;\n            }\n        }\n\n};\n\n\n\n\n\nReverse words in a String\nLearned about input stringstream have to check soem more regarding stringstream operation.\nclass Solution {\npublic:\n    string reverseWords(string s) {\n        std::istringstream tmp(s);\n        std::stringstream ss;\n        std::vector<std::string> collection((std::istream_iterator<std::string>(tmp)),std::istream_iterator<std::string>());\n        for (std::vector<std::string>::iterator it=collection.begin();it!=collection.end();it++){\n            std::reverse((*it).begin(),(*it).end());\n            ss << *it << \" \";  \n        }\n    std::string result = ss.str();\n    result.pop_back();\n    return result;\n    }\n};\n\n\n\nEncode and Decode TinyURL\nLearned about find operation in unordered::map container it returns an const_iterator which points to the given key. If the map doesn't have the key then it will return map.end().\nclass Solution {\npublic:\n    std::unordered_map<std::string,std::string> urlencodebuck;\n    std::unordered_map<std::string,std::string> urldecodebuck;\n    std::string alphanum = \"abcdefghijklmnopqrstuvwxyz0123456789\";\n    std::unordered_map<std::string,std::string>::const_iterator check;\n\n    // Encodes a URL to a shortened URL.\n    string encode(string longUrl) {\n        check = urlencodebuck.find(longUrl);\n        if(check != urlencodebuck.end())\n            return urlencodebuck[longUrl];\n        else{\n            std::string shortUrl = \"\";\n            for(int i=0;i<6;i++){\n                shortUrl = shortUrl + alphanum[(rand() % 36)];\n            }\n            urlencodebuck[longUrl] = shortUrl;\n            urldecodebuck[shortUrl] = longUrl;\n            return urlencodebuck[longUrl];\n        }\n    }\n\n    // Decodes a shortened URL to its original URL.\n    string decode(string shortUrl) {\n        return urldecodebuck[shortUrl];\n    }\n};\n\n\n\n\nProject Euler\n\nMultiples of 3 & 5 below 1000\nTime taken: 0.00006s\n#include <iostream>\n#include <time.h>\n\nint main(){\n    clock_t tStart = clock();\n    int multiple_3=0,multiple_5=0,multiple_15=0,i=0,sum=0;\n    while(multiple_5 <1000){\n        sum = sum + multiple_3 + multiple_5;\n        multiple_3 = multiple_3 + 3;\n        multiple_5 = multiple_5 + 5;\n        // multiple_5 = Multiple5(multiple_5);\n    }\n\n    while(multiple_3<1000){\n        sum = sum + multiple_3;\n        multiple_3 = multiple_3 + 3;\n    }\n    while(multiple_15<1000){\n        sum = sum - multiple_15;\n        multiple_15 = multiple_15 + 15;\n    }\n    std::cout << sum << '\\n';\n    printf(\"Time taken: %.5fs\\n\", (double)(clock() - tStart)/CLOCKS_PER_SEC);\n    return 0;\n} \n\n\n\nMy submission\nTime taken: 0.00007s\n#include <iostream>\n#include <time.h>\n\n\nint Multiple5(int multiple_5){\n    if (multiple_5%3==0){\n        multiple_5 = multiple_5 + 5;\n        Multiple5(multiple_5);\n    }\n    else\n        return multiple_5;\n\n}\n\nint main(){\n    clock_t tStart = clock();\n    int multiple_3=0,multiple_5=0,multiple_15=0,i=0,sum=0;\n    while(multiple_5 <1000){\n        sum = sum + multiple_3 + multiple_5;\n        multiple_3 = multiple_3 + 3;\n        multiple_5 = multiple_5 + 5;\n        multiple_5 = Multiple5(multiple_5);\n    }\n\n    while(multiple_3<1000){\n        sum = sum + multiple_3;\n        multiple_3 = multiple_3 + 3;\n    }\n\n    std::cout << sum << '\\n';\n    printf(\"Time taken: %.5fs\\n\", (double)(clock() - tStart)/CLOCKS_PER_SEC);\n    return 0;\n}",
      "tags": "Practice,Programming",
      "url": "https://thestrawh8.netlify.com/posts/programming_practice.html"
    },
    {
      "title": "My personal feelings",
      "text": "function rc4(key, str) {\n    var s = [], j = 0, x, res = '';\n    for (var i = 0; i < 256; i++) {\n        s[i] = i;\n    }\n    for (i = 0; i < 256; i++) {\n        j = (j + s[i] + key.charCodeAt(i % key.length)) % 256;\n        x = s[i];\n        s[i] = s[j];\n        s[j] = x;\n    }\n    i = 0;\n    j = 0;\n    for (var y = 0; y < str.length; y++) {\n        i = (i + 1) % 256;\n        j = (j + s[i]) % 256;\n        x = s[i];\n        s[i] = s[j];\n        s[j] = x;\n        res += String.fromCharCode(str.charCodeAt(y)  s[(s[i] + s[j]) % 256]);\n    }\n    return res;\n}\nfunction decrypt() {\n    key = $(\"#key\").val();\n    crypt_div = $(\"#encr\")\n    crypted = crypt_div.html();\n    decrypted = rc4(key, window.atob(crypted));\n    if (decrypted.substr(decrypted.length - 11) == \"<!--tail-->\"){\n        crypt_div.html(decrypted);\n        $(\"#pwform\").hide();\n        crypt_div.show();\n    } else { alert(\"Wrong password\"); };\n}\n\n\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\n\n\n\nThis post is password-protected.\n\nShow Content",
      "tags": "",
      "url": "https://thestrawh8.netlify.com/stories/personal.html"
    },
    {
      "title": "Deep Learning Setup",
      "text": "Specifications\n\nOS - Ubuntu 16.04\nGraphics - Nvidia Optimus (GTX1070 + IntelHD)\n\n\nAfter fresh installation of Ubuntu 16.04 \"Disabling nouveau driver\"\n\nsudo apt-get update\nsudo apt-get upgrade\n\n\n\n\n\nInstall one editor which you like the most\nsudo apt-get install vim\n\n\n\nBefore installing Drivers into your Hybrid system first we need to disable the nouveau (default display driver comes with linux) because it comes above all. Press 'CTRL+Alt+F1' you will enter shell now enter your username and password credentials and then continue\nsudo vim /etc/modprobe.d/blacklist.conf\n\n\n\nNow add the following lines in the end of the file ( Save & Exit)\nblacklist nouveau\nblacklist lbm-nouveau\noptions nouveau modeset=0\nalias nouveau off\nalias lbm-nouveau off\n\n\n\nNow get back to terminal and enter the following and later update the kernel and reboot\necho options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf\nsudo update-initramfs -u\nsudo reboot\n\n\n\n\nIntel+Nvidia GPU working setup using bumblebee and primus\n\nBasically using primus we can switch between the graphics and we take the help of bumblebee to make it smooth and we also take the help of a GUI indicator to make the transistions more simple.\nAdd the following repositories\nsudo apt-add-repository ppa:graphics-drivers\nsudo apt-add-repository ppa:bumblebee/testing\nsudo apt-add-repository ppa:nilarimogard/webupd8\nsudo apt-get update\n\n\n\nGo to Settings >> Software & Updates >> Additional Drivers\nSelect Nvidia-378 driver (because it is stable and it worked for me) and click on Apply and then Restart the system.\nAfter Restarting you can see the Nvidia-driver being selected as the display driver which previously was Xorg's nouveau.For further conforamtion you can check with the following command and the output will be comething like this.\nnvidia-smi\n\n[root@localhost release]# nvidia-smi\nWed Sep 26 23:16:16 2012       \n+------------------------------------------------------+                       \n| NVIDIA-SMI 3.295.41   Driver Version: 295.41         |                       \n|-------------------------------+----------------------+----------------------+\n| Nb.  Name                     | Bus Id        Disp.  | Volatile ECC SB / DB |\n| Fan   Temp   Power Usage /Cap | Memory Usage         | GPU Util. Compute M. |\n|===============================+======================+======================|\n| 0.  Tesla C2050               | 0000:05:00.0  On     |         0          0 |\n|  30%   62 C  P0    N/A /  N/A |   3%   70MB / 2687MB |   44%     Default    |\n|-------------------------------+----------------------+----------------------|\n| Compute processes:                                               GPU Memory |\n|  GPU  PID     Process name                                       Usage      |\n|=============================================================================|\n|  0.  7336     ./align                                                 61MB  |\n+-----------------------------------------------------------------------------+\n\n\n\nNow either use command line or Synaptics Manager to install the requirements inorder to keep it simple I shall use Synaptic Manager to demonstrate\n1) Enter bumblebee in the search dialog then you will be able to see bumblebee, bumblebee-nvidia, primus select all the three and Mark up for Installation and then click Apply\n2) After installing above three we check for bbswitch-dkms in search dialog box.It can be seen as already installed ( if not then install it)\nWe get back to our terminal and take the help of prime to select Intel Graphics as primary\nsudo prime-select intel\nsudo reboot\n\n\n\nNow enter prime-indicator(/plus) in search and mark up for installation and restart your system.\nInorder to make the bumblebee and bbswitch to take care of your system and use latest nvidia driver which has been installed go to the following file and edit\nsudo vim /etc/bumblebee/bumblebee.conf\n\n\n\nNow update the following contents\nDriver= should be changed to\nDriver=nvidia\n\n\n\nIn [driver-nvidia] section replace all nvidia-current terms to nvidia-378(If you have installed 378 or else replace it with the driver number which has been installed) and also in the same section replace\nPMMethod=auto\nPMMethod=bbswitch\n\n\n\nNow restart\nsudo reboot\n\n\n\nWe are done with our Nvidia driver installation and we also can switch between Intel and Nvidia Graphics which will help with saving the battery\n\nInstallation of CUDA-8.0 and verifying if it works or not\n\nNow switch to Nvidia Graphics and download the run file. In my case I have downloaded cuda_8.0.61_375.26_linux.run file because previous ones need a below 4.9 gcc compiler but when it comes to 16.04 by defualt it installs gcc-5.0 and the installation of Caffe requires a gcc-5 compiler to work ( portbuf). After downloading go to the specific folder and then\nchmod 755 cuda_8.0.61_375.26_linux.run\nsudo ./cuda_8.0.61_375.26_linux.run\n\n\n\nEnter no when asked to install Nvidia driver and rest all can be entered as Yes.\nDon't worry if it shows something like this\n===========\n\n= Summary =\n\n===========\n\nDriver: Not Selected\n\nToolkit: Installed in /usr/local/cuda-8.0\n\nSamples: Installed in /home/username, but missing recommended libraries\n\nPlease make sure that\n\n- PATH includes /usr/local/cuda-8.0/bin\n\n- LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root\n\nTo uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin\n\nPlease see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA.\n\n***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work.\n\n\n\nNow (Optional not required)\nsudo modprobe nvidia\n\n\n\nsudo vim /etc/profile\n\nand enter in the end\n\nexport PATH=/usr/local/cuda-8.0/bin:$PATH  \nexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\n\n\n\nNow save & exit\nsudo ldconfig\n\n\n\nThe setup is complete for CUDA now it's time to verify this\nsudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev  libglu1-mesa libglu1-mesa-dev libgl1-mesa-glx  \n\n\n\nNow go to the location where samples folder is installed by default it is installed at ~/\ncd into the samples directory\ncd 1_Utilities/deviceQuery\nsudo make\nsudo ./deviceQuery\n\n\n\nit should show something like this\nDevice 0: Quadro M1000M\n  CUDA Driver Version / Runtime Version          8.0 / 7.5\n  CUDA Capability Major/Minor version number:    5.0\n  Total amount of global memory:                 2002 MBytes (2099642368 bytes)\n  ( 4) Multiprocessors, (128) CUDA Cores/MP:     512 CUDA Cores\n  GPU Max Clock rate:                            1072 MHz (1.07 GHz)\n  Memory Clock rate:                             2505 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 2097152 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     No\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 7.5, NumDevs = 1, Device0 = Quadro M1000M\nResult = PASS\n\n\n\nSimilarly we conduct the bandwidth test which will also show PASS something similar to above  and then we confirm its installation. If it shows fail then there is some error in CUDA installation.\ncd ..\ncd bandwidthTest\nsudo make\nsudo ./bandwidthTest\n\n\n\nWith this we are ready with our system to use CUDA and NVIDIA GPU.\n\nInstallation of CUDNN (Easiest of All I should say)\n\nGo to Nvidia's site and download cuDNN ( I myself used cuDNN 5.1) you will get almost 98MB file now extract the contents and go to the extracted folder\ncd /cuda\nsudo cp -P include/cudnn.h /usr/include\nsudo cp -P lib64/libcudnn* /usr/lib/x86_64-linux-gnu/\nsudo chmod a+r /usr/lib/x86_64-linux-gnu/libcudnn*\n\n\n\n\nInstalling OpenCV3.2 (may not be complete but is enough for working with caffe)\n\nIn Ubuntu 16.04, install the dependencies first and then build the OpenCV 3.2 from source.\nsudo apt-get install --assume-yes build-essential cmake git\nsudo apt-get install --assume-yes pkg-config unzip ffmpeg qtbase5-dev python-dev python3-dev python-numpy python3-numpy\nsudo apt-get install --assume-yes libopencv-dev libgtk-3-dev libdc1394-22 libdc1394-22-dev libjpeg-dev libpng12-dev libtiff5-dev libjasper-dev\nsudo apt-get install --assume-yes libavcodec-dev libavformat-dev libswscale-dev libxine2-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev\nsudo apt-get install --assume-yes libv4l-dev libtbb-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev\nsudo apt-get install --assume-yes libvorbis-dev libxvidcore-dev v4l-utils python-vtk\nsudo apt-get install --assume-yes liblapacke-dev libopenblas-dev checkinstall\nsudo apt-get install --assume-yes libgdal-dev\n\n\n\nDownload the latest source archive for OpenCV 3.2 from https://github.com/opencv/opencv/archive/3.2.0.zip\nEnter the unpacked directory. Execute\nmkdir build\ncd build/    \ncmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D FORCE_VTK=ON -D WITH_TBB=ON -D WITH_V4L=ON -D WITH_QT=ON -D WITH_OPENGL=ON -D WITH_CUBLAS=ON -D CUDA_NVCC_FLAGS=\"-D_FORCE_INLINES\" -D WITH_GDAL=ON -D WITH_XINE=ON -D BUILD_EXAMPLES=ON ..\nmake -j $(($(nproc) + 1))\n\n\n\nTo complete the installation execute the following\nsudo make install\nsudo /bin/bash -c 'echo \"/usr/local/lib\" > /etc/ld.so.conf.d/opencv.conf'\nsudo ldconfig\nsudo apt-get update\n\n\n\nVerify installation with\npython\n>>> import cv2\n\n\n\nif it doesn't work then there is some error with OpenCV3.2 installation\nWith this we are done with our OpenCV3 installation next we jump into Caffe installation\n\nInstalling Caffe in 16.04 along with support of OpenCV3 & GPU (CUDA+cuDNN)\n\nFor pre-requisites we execute the following lines\nsudo apt-get update\nsudo apt-get upgrade\n\nsudo apt-get install -y build-essential cmake git pkg-config\nsudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\nsudo apt-get install -y libatlas-base-dev\nsudo apt-get install -y --no-install-recommends libboost-all-dev\nsudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev\n\n# (Python general)\nsudo apt-get install -y python-pip\n\n# (Python 2.7 development files)\nsudo apt-get install -y python-dev\nsudo apt-get install -y python-numpy python-scipy\n\n\n\nWe next clone the Caffe repo.\ncd ~\ngit clone https://github.com/BVLC/caffe.git\n\n\n\nWe make changes in Makefile.config and Makefile and configure to proceed the Caffe installation smoothly.\ncd ~/caffe\ncp Makefile.config.example Makefile.config\nsudo vim Makefile.config\n\n\n\nWe now make the following changes and configure the copied Makefile.config (by uncommenting and editing the following lines in the file)\nUSE_CUDNN := 1\nOPENCV_VERSION := 3\n\nChange\nCUDA_DIR := /usr/local/cuda\nto\nCUDA_DIR := /usr/local/cuda-8.0\n\nPYTHON_INCLUDE := /usr/include/python2.7 /usr/lib/python2.7/dist-packages/numpy/core/include\nWITH_PYTHON_LAYER := 1\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial\n\n\n\nSomtimes the PYTHON_INCLUDE may differ in some systems check for the presence of numpy core files\nPYTHON_INCLUDE := /usr/include/python2.7 /usr/local/lib/python2.7/dist-packages/numpy/core/include  \nWITH_PYTHON_LAYER := 1  \nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial  \nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial\n\n\n\nNow edit Makefile ( above we edited Makefile.config)\ncd ~/caffe\nsudo vim Makefile\n\nChange\nNVCCFLAGS += -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)\nto\nNVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)\n\n\n\nNow we install some python requirements by taking pip's help\ncd ~/caffe/python\nfor req in $(cat requirements.txt); do sudo -H pip install $req --upgrade; done\n\n\n\nNow it's time to check make and check caffe's installation\ncd ~/caffe\nmake all -j $(($(nproc) + 1))\nmake test\nmake runtest\n\nmake pycaffe\nmake distribute\n\nsudo vim ~/.bashrc\nadd the follwing line to the file\nexport PYTHONPATH=~/caffe/python:$PYTHONPATH\nsource ~/.bashrc\n\n\n\nNow you can verify your installation with (for python2.7)\npython\n>>> import caffe\n\n\n\nWith this we are ready with are our Deep Learning setup it's now time to become the Pirate King!",
      "tags": "Caffe,Graphics-drivers,Learning Thoery",
      "url": "https://thestrawh8.netlify.com/posts/deeplearning_setup.html"
    },
    {
      "title": "Audio Drivers Installion",
      "text": "It has been that there is a requirement of 4.11 kernel version for Realtek-ALC1220 to support. So if you too built a your new PC like me then it might be helpful to you for temporary replacement. Uninstall your alsa-base and reinstall latest version it will work fine.\nsudo apt-get remove alsa-base\n\n\n\nNow go to http://www.stchman.com/tools/alsa/alsa_setup.sh and download the script and then do\nsudo ./alsa_setup.sh\n\n\n\nThis will reinstall the lastest driver in your system and reboots it.\n Precautions if you are having Hybrid Graphics(Intel + Nvidia) then it is suggested to run on Intel HD Graphics and then install. Because this driver is supported for Intel HDA versions if you try to install when you are running in NVIDIA this might cause several failures.",
      "tags": "Audio driver",
      "url": "https://thestrawh8.netlify.com/posts/audiodrivers_installation.html"
    },
    {
      "title": "Contact",
      "text": "I would like to use this as a platform to be thankful for the whole community who help others by sharing their knowledge and thoughts openly and help amateurs like us to grow. I would also start my journey of learning by sharing my knowledge and views. I will be very happy to discuss with everyone either Academic or Non-Academic details.\n  \n  \n\n  \n    \n      \n        \n          Please do share your Feedback   \n        \n          Name\n          \n          You really do have a nice name.\n            \n        \n          Email address\n          \n          Will never share your email with anyone else.\n        \n        \n          Share your Feedback\n          \n          Thanks for sharing your thoughts with me.\n        \n        Submit\n  \n  \n  \n  \n\n\n  \n    \n      Contact details\n      \n        \n          Monkey D Luffy \n          thestrawh8@gmail.com \n          3rd Floor, \n          SBI Building, \n          Rajendra Nagar, \n          Gudivada, \n        Andhra Pradesh.",
      "tags": "",
      "url": "https://thestrawh8.netlify.com/stories/contact.html"
    },
    {
      "title": "About",
      "text": "Random Dots\n      \n        I have committed sins, I want to clean myself & work towards becoming a \u0938\u094d\u0925\u093f\u0924\u092a\u094d\u0930\u091c\u094d\u091e\u0938\u094d\u092f\"\n    \n    \n\n\n  All is one, One is All\n  \n    I always struggle in aligning thoughts to get the better complete view which will answer everything. So I was trying to figure out the kind of life I want to lead and principles which I should stick to, Surprisingly everything was converging to single point and I was only able to align to one kind of lifestyle. I could clearly see everytime I admire some character I try to see my reflection in them and which makes me even more clear about my life. Such great convergence I could see in the Shiva, Hanuman, Karna, Luffy all have the same core values.\n    \n    \n   \n    \n      Self Control\n      Kindness\n      Dedication towards their duties(Dharma)\n      Selflessness\n      Sticking to Promise\n      Skill\n      Purity\n      Stand up for ones who believe in me\n      \n    These core values are all the same for them. I want to lead a life which will make me stick to these core values.\n  \n\n\n\n\n\n  \n        Projects\n        Education\n        \n      \n      \n\n      \n        \n        \n      \n        \n          \n            Interests\n          Deep Learning, Variational Methods, Kernel Methods, Optimization Mathods, 3D Facial Reconstruction, Multi view Stereo, Statistical Modelling methods, Bayesian Methods, Probablitic Graphical Models, Manifold methods in Machine Learning,Deep Reinforcement Learning, Multi arm Bandits, Semantic Segmentation, Pose Estimation, Statistical Signal Processing, Group theoritic & Differential geometric projections on Machine Learning, Scalability, Advanced Algorithms & Data Structures, Competitive-Programming, Chess, One-Piece Anime, Music & Blogging.\n            Research Projects\n                Variational Bayesian Matrix Factorization of Bounded Support Data:\n                  Guide: Prof. Anirban M. (implementation of IEEE Transaction on Pattern Analysis and Machine Intelligence-2015.)\n                  Cancer epigenomic analysis,Prediction of missing data in the images,Source-Seperation and Source-Reconstruction by BG-NMF technique.\n                Baler Weights Variation in PBR Plant:\n                  Designed a Prototype of low cost \"Feedback System\" for reduction of weight variation caused during the opening and closing of baler gates\n                Analysed Load cell architecture and operating, frequency ranges and recommended cost effective solutions which after implementation reduced the variation from 350gm to 150 gm exceeding the standard efficiency of Baler Corp.\n                Modelling the Transitions in Lung cancer cells and classification of different cells using Deep Belief Networks.:\n                  Modelling different stages of epigenomic cells and classifying them into 4 different transition stages with an accuracy of 97.5% and 89.9% respectively for binary and multi-class problems.\n                Measurement of fiber angular orientation distributions of the objects in the images:\n                  Using the fourier components for determining the orientation. Can be used to identify the alignment of objects with good accuracy.\n                ARMS-Robotic Arm Sleeves:\n                  Interfaced EMG sensors and IMU with a robotic arm using Xigbee protocol and Atmega 16 microcontroller for mimicing the human arm movements.(group project)\n                Examination of various feature extraction and selection techniques for binary classification problem of Right half and Left half brain activity based on EEG signals.:\n                  Guide: Prof. Manjunatha M.\n                  Performing Pre processing using STFT transformation and using alpha,beta,etc. components as features to classify.\n                Design and Construction of a low cost Digital PH-meter using constant phase element as sensor:\n                  Guide: Prof. Karabi B.\n                  Designed and constructed a low cost PH-meter from scratch using Operational-Amplifiers and Logic gates(for conditioning the output of sensing element, PMMA, DQN-70 coated probes.\n                Analog circuit design for Measuring Heart Rate and Blood flow rate - Plethysmography:\n                  Guide: Prof. Saraswat C.\n                  Designed and constructed circuitry for measuring the blood flow rate using plethysmography technique from basic Low-pass filters and Instrumentation Amplifiers.\n                Sanjeevani:\n                  Conceptualized and designed a prototype of a product which is made by bringing all kinds of card tests in one compact machine to detect conditions of diseases.(group project)\n          \n          \n        \n        \n      \n        \n        \n          System Software Engineer - II @Hewlett Packard Enterprise - Aruba R&D Sep 2016-Sep 2017\n              \n                Part of 12/39 members of Core Development team of Aruba-Clearpass who work from India (Rest in U.S)\n                Gained experience on full technology Stack from UI to Hibernate DB for Aruba Clearpass Security Product.\n                Started work from automation of REST API\u2019s using Python and continued work on UI(Javascript) and Java Backend Operations and Hibernate DB. Made a good number of feature additions to the product as a part of upgrade -6.7 and actively participated to take decisions for product\u2019s security aspect future from AI point of view.\n              \n          Summer Internship - Baler Weight Variation in PBR @ Reliance-Industries May 2015-Jul 2015\n              Designed a Prototype of low cost \"Feedback System\" for reduction of weight variation caused during the opening and closing of baler gates\n                Analysed Load cell architecture and operating, frequency ranges and recommended cost effective solutions which after implementation reduced the variation from 350gm to 150 gm exceeding the standard efficiency of Baler Corp.\n          Bachelors of Technology in Instrumentation Engineering, 2012-2016:\n            \n            Indian Institute of Technology Kharagpur, India\n              Honours Thesis: Variational Bayesian Matrix Factorization of Bounded Support Data\n              \n              Extra-Activities:\n              Part of Gold winning Ad-Design-(2013), Product-Design-(2014) teams of Nehru Hall of Residence\n                Key member in conceptualizing the ideas for Product-Design-(2013), Hardware-Modelling-(2013) events of Nehru Hall of Residence.\n                Part of Hockey and Chemical Innovation Teams of Nehru Hall of Residence.           \n              Honours and Achievements: \n                Awarded for presenting an Idea on Detection of DDOS attacks using Deep Learning techniques by monitoring the Network Packet Flow at HPE - Aruba Networks.\n                  Received an Excellence Award from the site president of Reliance Industries and was the only intern to get this award among 90 interns from various IIT\u2019s ans NIT\u2019s in that year.\n                  Received a Pre-Placement Offer from Reliance Industries.\n                  Secured a rank in top 0.1,1% in AIEEE and JEE.\n\n        \n          Intermediate Examination Board of Andhra Pradesh, 2010-2012\n            GPA: 9.43\n        \n          Secondary School Certificate Board of Andhra Pradesh, 2010\n            GPA: 9.37",
      "tags": "",
      "url": "https://thestrawh8.netlify.com/stories/about.html"
    }
  ]
}