<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Deep Learning Setup | Random Connected Dots</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="https://thestrawh8.netlify.com/posts/deeplearning_setup.html">
<link rel="icon" href="images/favicon-32x32.png" sizes="32x32">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><link rel="stylesheet" type="text/css" href="../assets/css/tipuesearch.css">
<meta name="author" content="thestrawh8">
<link rel="prev" href="audiodrivers_installation.html" title="Audio Drivers Installion" type="text/html">
<link rel="next" href="twitter-bird-using-dqn-a-review.html" title="Twitter Bird using DQN - a review" type="text/html">
<meta property="og:site_name" content="Random Connected Dots">
<meta property="og:title" content="Deep Learning Setup">
<meta property="og:url" content="https://thestrawh8.netlify.com/posts/deeplearning_setup.html">
<meta property="og:description" content='Specifications

OS - Ubuntu 16.04
Graphics - Nvidia Optimus (GTX1070 + IntelHD)


After fresh installation of Ubuntu 16.04 "Disabling nouveau driver"

sudo apt-get update
sudo apt-get upgrade





Ins'>
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-11-23T07:24:00+05:30">
<meta property="article:tag" content="Caffe">
<meta property="article:tag" content="Graphics-drivers">
<meta property="article:tag" content="Learning Thoery">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-default navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://thestrawh8.netlify.com/">

            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../stories/about.html">About</a>
                </li>
<li>
<a href="../">Blog</a>
            </li>
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Progress <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li>
<a href="../stories/theory.html">Machine Learning Theory</a>
                    </li>
<li>
<a href="../stories/practice.html">Machine Learning Practice</a>
                    </li>
<li>
<a href="../stories/programming.html">Programming</a>
            </li>
</ul>
</li>
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Archive <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li>
<a href="../archive.html">Archive</a>
                    </li>
<li>
<a href="../categories/index.html">Tags</a>
            </li>
</ul>
</li>
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Personal <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li>
<a href="../stories/personal.html">Secrets</a>
                    </li>
<li>
<a href="../stories/schedule.html">Complete Schedule</a>
                    </li>
<li>
<a href="../stories/theoryguide.html">Theory Schedule</a>
            </li>
</ul>
</li>
<li>
<a href="../stories/contact.html">Contact</a>

                
            </li>
</ul>
<span class="navbar-form navbar-right">
    <input type="text" id="tipue_search_input" class="form-control" placeholder="Search"></span>

            <!-- <ul class="nav navbar-nav navbar-right">
                
                
                
            </ul> -->
        </div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="#" class="u-url">Deep Learning Setup</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    thestrawh8
            </span></p>
            <p class="dateline"><a href="#" rel="bookmark"><time class="published dt-published" datetime="2017-11-23T07:24:00+05:30" itemprop="datePublished" title="2017-11-23 07:24">2017-11-23 07:24</time></a></p>
                <p class="commentline">
        
    <a href="deeplearning_setup.html#disqus_thread" data-disqus-identifier="cache/posts/deeplearning_setup.html">Comments</a>


            

        </p>
</div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<h3>Specifications</h3>
<ul>
<li>OS - Ubuntu 16.04</li>
<li>Graphics - Nvidia Optimus (GTX1070 + IntelHD)</li>
</ul>
<blockquote>
<p>After fresh installation of Ubuntu 16.04 "Disabling nouveau driver"</p>
</blockquote>
<pre class="code literal-block"><span></span>sudo apt-get update
sudo apt-get upgrade
</pre>


<!-- TEASER_END -->

<p>Install one editor which you like the most</p>
<pre class="code literal-block"><span></span>sudo apt-get install vim
</pre>


<p>Before installing Drivers into your Hybrid system first we need to disable the nouveau (default display driver comes with linux) because it comes above all. Press 'CTRL+Alt+F1' you will enter shell now enter your username and password credentials and then continue</p>
<pre class="code literal-block"><span></span>sudo vim /etc/modprobe.d/blacklist.conf
</pre>


<p>Now add the following lines in the end of the file ( Save &amp; Exit)</p>
<pre class="code literal-block"><span></span>blacklist nouveau
blacklist lbm-nouveau
options nouveau <span class="nv">modeset</span><span class="o">=</span><span class="m">0</span>
<span class="nb">alias</span> nouveau off
<span class="nb">alias</span> lbm-nouveau off
</pre>


<p>Now get back to terminal and enter the following and later update the kernel and reboot</p>
<pre class="code literal-block"><span></span><span class="nb">echo</span> options nouveau <span class="nv">modeset</span><span class="o">=</span><span class="m">0</span> <span class="p">|</span> sudo tee -a /etc/modprobe.d/nouveau-kms.conf
sudo update-initramfs -u
sudo reboot
</pre>


<blockquote>
<p>Intel+Nvidia GPU working setup using bumblebee and primus</p>
</blockquote>
<p>Basically using primus we can switch between the graphics and we take the help of bumblebee to make it smooth and we also take the help of a GUI indicator to make the transistions more simple.</p>
<p>Add the following repositories</p>
<pre class="code literal-block"><span></span>sudo apt-add-repository ppa:graphics-drivers
sudo apt-add-repository ppa:bumblebee/testing
sudo apt-add-repository ppa:nilarimogard/webupd8
sudo apt-get update
</pre>


<p>Go to Settings &gt;&gt; Software &amp; Updates &gt;&gt; Additional Drivers
Select Nvidia-378 driver (because it is stable and it worked for me) and click on Apply and then Restart the system.</p>
<p>After Restarting you can see the Nvidia-driver being selected as the display driver which previously was Xorg's nouveau.For further conforamtion you can check with the following command and the output will be comething like this.</p>
<pre class="code literal-block"><span></span>nvidia-smi

<span class="o">[</span>root@localhost release<span class="o">]</span><span class="c1"># nvidia-smi</span>
Wed Sep <span class="m">26</span> <span class="m">23</span>:16:16 <span class="m">2012</span>       
+------------------------------------------------------+                       
<span class="p">|</span> NVIDIA-SMI <span class="m">3</span>.295.41   Driver Version: <span class="m">295</span>.41         <span class="p">|</span>                       
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span> Nb.  Name                     <span class="p">|</span> Bus Id        Disp.  <span class="p">|</span> Volatile ECC SB / DB <span class="p">|</span>
<span class="p">|</span> Fan   Temp   Power Usage /Cap <span class="p">|</span> Memory Usage         <span class="p">|</span> GPU Util. Compute M. <span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span> <span class="m">0</span>.  Tesla C2050               <span class="p">|</span> <span class="m">0000</span>:05:00.0  On     <span class="p">|</span>         <span class="m">0</span>          <span class="m">0</span> <span class="p">|</span>
<span class="p">|</span>  <span class="m">30</span>%   <span class="m">62</span> C  P0    N/A /  N/A <span class="p">|</span>   <span class="m">3</span>%   70MB / 2687MB <span class="p">|</span>   <span class="m">44</span>%     Default    <span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------<span class="p">|</span>
<span class="p">|</span> Compute processes:                                               GPU Memory <span class="p">|</span>
<span class="p">|</span>  GPU  PID     Process name                                       Usage      <span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span>  <span class="m">0</span>.  <span class="m">7336</span>     ./align                                                 61MB  <span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre>


<p>Now either use command line or Synaptics Manager to install the requirements inorder to keep it simple I shall use Synaptic Manager to demonstrate</p>
<p>1) Enter bumblebee in the search dialog then you will be able to see bumblebee, bumblebee-nvidia, primus select all the three and Mark up for Installation and then click Apply
2) After installing above three we check for bbswitch-dkms in search dialog box.It can be seen as already installed ( if not then install it)</p>
<p>We get back to our terminal and take the help of prime to select Intel Graphics as primary</p>
<pre class="code literal-block"><span></span>sudo prime-select intel
sudo reboot
</pre>


<p>Now enter prime-indicator(/plus) in search and mark up for installation and restart your system.
Inorder to make the bumblebee and bbswitch to take care of your system and use latest nvidia driver which has been installed go to the following file and edit</p>
<pre class="code literal-block"><span></span>sudo vim /etc/bumblebee/bumblebee.conf
</pre>


<p>Now update the following contents</p>
<pre class="code literal-block"><span></span><span class="nv">Driver</span><span class="o">=</span> should be changed to
<span class="nv">Driver</span><span class="o">=</span>nvidia
</pre>


<p>In [driver-nvidia] section replace all nvidia-current terms to nvidia-378(If you have installed 378 or else replace it with the driver number which has been installed) and also in the same section replace</p>
<pre class="code literal-block"><span></span><span class="nv">PMMethod</span><span class="o">=</span>auto
<span class="nv">PMMethod</span><span class="o">=</span>bbswitch
</pre>


<p>Now restart</p>
<pre class="code literal-block"><span></span>sudo reboot
</pre>


<p>We are done with our Nvidia driver installation and we also can switch between Intel and Nvidia Graphics which will help with saving the battery</p>
<blockquote>
<p>Installation of CUDA-8.0 and verifying if it works or not</p>
</blockquote>
<p>Now switch to Nvidia Graphics and download the run file. In my case I have downloaded <code>cuda_8.0.61_375.26_linux.run</code> file because previous ones need a below 4.9 gcc compiler but when it comes to 16.04 by defualt it installs gcc-5.0 and the installation of Caffe requires a gcc-5 compiler to work ( portbuf). After downloading go to the specific folder and then</p>
<pre class="code literal-block"><span></span>chmod <span class="m">755</span> cuda_8.0.61_375.26_linux.run
sudo ./cuda_8.0.61_375.26_linux.run
</pre>


<p>Enter no when asked to install Nvidia driver and rest all can be entered as Yes.
Don't worry if it shows something like this</p>
<pre class="code literal-block"><span></span><span class="o">===========</span>

<span class="o">=</span> <span class="nv">Summary</span> <span class="o">=</span>

<span class="o">===========</span>

Driver: Not Selected

Toolkit: Installed in /usr/local/cuda-8.0

Samples: Installed in /home/username, but missing recommended libraries

Please make sure that

- PATH includes /usr/local/cuda-8.0/bin

- LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root

To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin

Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf <span class="k">for</span> detailed information on setting up CUDA.

***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least <span class="m">361</span>.00 is required <span class="k">for</span> CUDA <span class="m">8</span>.0 functionality to work.
</pre>


<p>Now (Optional not required)</p>
<pre class="code literal-block"><span></span>sudo modprobe nvidia
</pre>


<pre class="code literal-block"><span></span>sudo vim /etc/profile

and enter in the end

<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span>/usr/local/cuda-8.0/bin:<span class="nv">$PATH</span>  
<span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/local/cuda-8.0/lib64:<span class="nv">$LD_LIBRARY_PATH</span>
</pre>


<p>Now save &amp; exit</p>
<pre class="code literal-block"><span></span>sudo ldconfig
</pre>


<p>The setup is complete for CUDA now it's time to verify this</p>
<pre class="code literal-block"><span></span>sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev  libglu1-mesa libglu1-mesa-dev libgl1-mesa-glx  
</pre>


<p>Now go to the location where samples folder is installed by default it is installed at ~/</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> into the samples directory
<span class="nb">cd</span> 1_Utilities/deviceQuery
sudo make
sudo ./deviceQuery
</pre>


<p>it should show something like this</p>
<pre class="code literal-block"><span></span>Device <span class="m">0</span>: Quadro M1000M
  CUDA Driver Version / Runtime Version          <span class="m">8</span>.0 / <span class="m">7</span>.5
  CUDA Capability Major/Minor version number:    <span class="m">5</span>.0
  Total amount of global memory:                 <span class="m">2002</span> MBytes <span class="o">(</span><span class="m">2099642368</span> bytes<span class="o">)</span>
  <span class="o">(</span> <span class="m">4</span><span class="o">)</span> Multiprocessors, <span class="o">(</span><span class="m">128</span><span class="o">)</span> CUDA Cores/MP:     <span class="m">512</span> CUDA Cores
  GPU Max Clock rate:                            <span class="m">1072</span> MHz <span class="o">(</span><span class="m">1</span>.07 GHz<span class="o">)</span>
  Memory Clock rate:                             <span class="m">2505</span> Mhz
  Memory Bus Width:                              <span class="m">128</span>-bit
  L2 Cache Size:                                 <span class="m">2097152</span> bytes
  Maximum Texture Dimension Size <span class="o">(</span>x,y,z<span class="o">)</span>         <span class="nv">1D</span><span class="o">=(</span><span class="m">65536</span><span class="o">)</span>, <span class="nv">2D</span><span class="o">=(</span><span class="m">65536</span>, <span class="m">65536</span><span class="o">)</span>, <span class="nv">3D</span><span class="o">=(</span><span class="m">4096</span>, <span class="m">4096</span>, <span class="m">4096</span><span class="o">)</span>
  Maximum Layered 1D Texture Size, <span class="o">(</span>num<span class="o">)</span> layers  <span class="nv">1D</span><span class="o">=(</span><span class="m">16384</span><span class="o">)</span>, <span class="m">2048</span> layers
  Maximum Layered 2D Texture Size, <span class="o">(</span>num<span class="o">)</span> layers  <span class="nv">2D</span><span class="o">=(</span><span class="m">16384</span>, <span class="m">16384</span><span class="o">)</span>, <span class="m">2048</span> layers
  Total amount of constant memory:               <span class="m">65536</span> bytes
  Total amount of shared memory per block:       <span class="m">49152</span> bytes
  Total number of registers available per block: <span class="m">65536</span>
  Warp size:                                     <span class="m">32</span>
  Maximum number of threads per multiprocessor:  <span class="m">2048</span>
  Maximum number of threads per block:           <span class="m">1024</span>
  Max dimension size of a thread block <span class="o">(</span>x,y,z<span class="o">)</span>: <span class="o">(</span><span class="m">1024</span>, <span class="m">1024</span>, <span class="m">64</span><span class="o">)</span>
  Max dimension size of a grid size    <span class="o">(</span>x,y,z<span class="o">)</span>: <span class="o">(</span><span class="m">2147483647</span>, <span class="m">65535</span>, <span class="m">65535</span><span class="o">)</span>
  Maximum memory pitch:                          <span class="m">2147483647</span> bytes
  Texture alignment:                             <span class="m">512</span> bytes
  Concurrent copy and kernel execution:          Yes with <span class="m">1</span> copy engine<span class="o">(</span>s<span class="o">)</span>
  Run <span class="nb">time</span> limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement <span class="k">for</span> Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing <span class="o">(</span>UVA<span class="o">)</span>:      Yes
  Device PCI Domain ID / Bus ID / location ID:   <span class="m">0</span> / <span class="m">1</span> / <span class="m">0</span>
  Compute Mode:
     &lt; Default <span class="o">(</span>multiple host threads can use with device simultaneously<span class="o">)</span> &gt;

deviceQuery, CUDA <span class="nv">Driver</span> <span class="o">=</span> CUDART, CUDA Driver <span class="nv">Version</span> <span class="o">=</span> <span class="m">8</span>.0, CUDA Runtime <span class="nv">Version</span> <span class="o">=</span> <span class="m">7</span>.5, <span class="nv">NumDevs</span> <span class="o">=</span> <span class="m">1</span>, <span class="nv">Device0</span> <span class="o">=</span> Quadro M1000M
<span class="nv">Result</span> <span class="o">=</span> PASS
</pre>


<p>Similarly we conduct the bandwidth test which will also show PASS something similar to above  and then we confirm its installation. If it shows fail then there is some error in CUDA installation.</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> ..
<span class="nb">cd</span> bandwidthTest
sudo make
sudo ./bandwidthTest
</pre>


<p>With this we are ready with our system to use CUDA and NVIDIA GPU.</p>
<blockquote>
<p>Installation of CUDNN (Easiest of All I should say)</p>
</blockquote>
<p>Go to Nvidia's site and download cuDNN ( I myself used cuDNN 5.1) you will get almost 98MB file now extract the contents and go to the extracted folder</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> /cuda
sudo cp -P include/cudnn.h /usr/include
sudo cp -P lib64/libcudnn* /usr/lib/x86_64-linux-gnu/
sudo chmod a+r /usr/lib/x86_64-linux-gnu/libcudnn*
</pre>


<blockquote>
<p>Installing OpenCV3.2 (may not be complete but is enough for working with caffe)</p>
</blockquote>
<p>In Ubuntu 16.04, install the dependencies first and then build the OpenCV 3.2 from source.</p>
<pre class="code literal-block"><span></span>sudo apt-get install --assume-yes build-essential cmake git
sudo apt-get install --assume-yes pkg-config unzip ffmpeg qtbase5-dev python-dev python3-dev python-numpy python3-numpy
sudo apt-get install --assume-yes libopencv-dev libgtk-3-dev libdc1394-22 libdc1394-22-dev libjpeg-dev libpng12-dev libtiff5-dev libjasper-dev
sudo apt-get install --assume-yes libavcodec-dev libavformat-dev libswscale-dev libxine2-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev
sudo apt-get install --assume-yes libv4l-dev libtbb-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev
sudo apt-get install --assume-yes libvorbis-dev libxvidcore-dev v4l-utils python-vtk
sudo apt-get install --assume-yes liblapacke-dev libopenblas-dev checkinstall
sudo apt-get install --assume-yes libgdal-dev
</pre>


<p>Download the latest source archive for OpenCV 3.2 from https://github.com/opencv/opencv/archive/3.2.0.zip</p>
<p>Enter the unpacked directory. Execute</p>
<pre class="code literal-block"><span></span>mkdir build
<span class="nb">cd</span> build/    
cmake -D <span class="nv">CMAKE_BUILD_TYPE</span><span class="o">=</span>RELEASE -D <span class="nv">CMAKE_INSTALL_PREFIX</span><span class="o">=</span>/usr/local -D <span class="nv">FORCE_VTK</span><span class="o">=</span>ON -D <span class="nv">WITH_TBB</span><span class="o">=</span>ON -D <span class="nv">WITH_V4L</span><span class="o">=</span>ON -D <span class="nv">WITH_QT</span><span class="o">=</span>ON -D <span class="nv">WITH_OPENGL</span><span class="o">=</span>ON -D <span class="nv">WITH_CUBLAS</span><span class="o">=</span>ON -D <span class="nv">CUDA_NVCC_FLAGS</span><span class="o">=</span><span class="s2">"-D_FORCE_INLINES"</span> -D <span class="nv">WITH_GDAL</span><span class="o">=</span>ON -D <span class="nv">WITH_XINE</span><span class="o">=</span>ON -D <span class="nv">BUILD_EXAMPLES</span><span class="o">=</span>ON ..
make -j <span class="k">$(($(</span>nproc<span class="k">)</span> <span class="o">+</span> <span class="m">1</span><span class="k">))</span>
</pre>


<p>To complete the installation execute the following</p>
<pre class="code literal-block"><span></span>sudo make install
sudo /bin/bash -c <span class="s1">'echo "/usr/local/lib" &gt; /etc/ld.so.conf.d/opencv.conf'</span>
sudo ldconfig
sudo apt-get update
</pre>


<p>Verify installation with</p>
<pre class="code literal-block"><span></span>python
&gt;&gt;&gt; import cv2
</pre>


<p>if it doesn't work then there is some error with OpenCV3.2 installation</p>
<p>With this we are done with our OpenCV3 installation next we jump into Caffe installation</p>
<blockquote>
<p>Installing Caffe in 16.04 along with support of OpenCV3 &amp; GPU (CUDA+cuDNN)</p>
</blockquote>
<p>For pre-requisites we execute the following lines</p>
<pre class="code literal-block"><span></span>sudo apt-get update
sudo apt-get upgrade

sudo apt-get install -y build-essential cmake git pkg-config
sudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler
sudo apt-get install -y libatlas-base-dev
sudo apt-get install -y --no-install-recommends libboost-all-dev
sudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev

<span class="c1"># (Python general)</span>
sudo apt-get install -y python-pip

<span class="c1"># (Python 2.7 development files)</span>
sudo apt-get install -y python-dev
sudo apt-get install -y python-numpy python-scipy
</pre>


<p>We next clone the Caffe repo.</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> ~
git clone https://github.com/BVLC/caffe.git
</pre>


<p>We make changes in Makefile.config and Makefile and configure to proceed the Caffe installation smoothly.</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> ~/caffe
cp Makefile.config.example Makefile.config
sudo vim Makefile.config
</pre>


<p>We now make the following changes and configure the copied Makefile.config (by uncommenting and editing the following lines in the file)</p>
<pre class="code literal-block"><span></span>USE_CUDNN :<span class="o">=</span> <span class="m">1</span>
OPENCV_VERSION :<span class="o">=</span> <span class="m">3</span>

Change
CUDA_DIR :<span class="o">=</span> /usr/local/cuda
to
CUDA_DIR :<span class="o">=</span> /usr/local/cuda-8.0

PYTHON_INCLUDE :<span class="o">=</span> /usr/include/python2.7 /usr/lib/python2.7/dist-packages/numpy/core/include
WITH_PYTHON_LAYER :<span class="o">=</span> <span class="m">1</span>
INCLUDE_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_INCLUDE<span class="k">)</span> /usr/local/include /usr/include/hdf5/serial
LIBRARY_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_LIB<span class="k">)</span> /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial
</pre>


<p>Somtimes the PYTHON_INCLUDE may differ in some systems check for the presence of numpy core files</p>
<pre class="code literal-block"><span></span>PYTHON_INCLUDE :<span class="o">=</span> /usr/include/python2.7 /usr/local/lib/python2.7/dist-packages/numpy/core/include  
WITH_PYTHON_LAYER :<span class="o">=</span> <span class="m">1</span>  
INCLUDE_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_INCLUDE<span class="k">)</span> /usr/local/include /usr/include/hdf5/serial  
LIBRARY_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_LIB<span class="k">)</span> /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial
</pre>


<p>Now edit Makefile ( above we edited Makefile.config)</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> ~/caffe
sudo vim Makefile

Change
<span class="nv">NVCCFLAGS</span> <span class="o">+=</span> -ccbin<span class="o">=</span><span class="k">$(</span>CXX<span class="k">)</span> -Xcompiler -fPIC <span class="k">$(</span>COMMON_FLAGS<span class="k">)</span>
to
<span class="nv">NVCCFLAGS</span> <span class="o">+=</span> -D_FORCE_INLINES -ccbin<span class="o">=</span><span class="k">$(</span>CXX<span class="k">)</span> -Xcompiler -fPIC <span class="k">$(</span>COMMON_FLAGS<span class="k">)</span>
</pre>


<p>Now we install some python requirements by taking pip's help</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> ~/caffe/python
<span class="k">for</span> req in <span class="k">$(</span>cat requirements.txt<span class="k">)</span><span class="p">;</span> <span class="k">do</span> sudo -H pip install <span class="nv">$req</span> --upgrade<span class="p">;</span> <span class="k">done</span>
</pre>


<p>Now it's time to check make and check caffe's installation</p>
<pre class="code literal-block"><span></span><span class="nb">cd</span> ~/caffe
make all -j <span class="k">$(($(</span>nproc<span class="k">)</span> <span class="o">+</span> <span class="m">1</span><span class="k">))</span>
make <span class="nb">test</span>
make runtest

make pycaffe
make distribute

sudo vim ~/.bashrc
add the follwing line to the file
<span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span>~/caffe/python:<span class="nv">$PYTHONPATH</span>
<span class="nb">source</span> ~/.bashrc
</pre>


<p>Now you can verify your installation with (for python2.7)</p>
<pre class="code literal-block"><span></span><span class="n">python</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">caffe</span>
</pre>


<p>With this we are ready with are our Deep Learning setup it's now time to become the Pirate King!</p>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../categories/caffe.html" rel="tag">Caffe</a></li>
            <li><a class="tag p-category" href="../categories/graphics-drivers.html" rel="tag">Graphics-drivers</a></li>
            <li><a class="tag p-category" href="../categories/learning-thoery.html" rel="tag">Learning Thoery</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="audiodrivers_installation.html" rel="prev" title="Audio Drivers Installion">Previous post</a>
            </li>
            <li class="next">
                <a href="twitter-bird-using-dqn-a-review.html" rel="next" title="Twitter Bird using DQN - a review">Next post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
        
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="https-thestrawh8-netlify-com",
            disqus_url="https://thestrawh8.netlify.com/posts/deeplearning_setup.html",
        disqus_title="Deep Learning Setup",
        disqus_identifier="cache/posts/deeplearning_setup.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="https-thestrawh8-netlify-com";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
        <!--End of body content-->

        <footer id="footer"></footer>
</div>
</div>


            <script src="../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(1, "DD MMM-YYYY HH:mm");
    </script><!-- end fancy dates --><!-- Modal --><div id="search-results" class="modal fade" role="dialog" style="height: 80%;">
      <div class="modal-dialog">
    
        <!-- Modal content-->
        <div class="modal-content">
          <div class="modal-header">
            <button type="button" class="close" data-dismiss="modal">×</button>
            <h4 class="modal-title">Search Results:</h4>
          </div>
          <div class="modal-body" id="tipue_search_content" style="max-height: 600px; overflow-y: auto;">
          </div>
          <div class="modal-footer">
            <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
          </div>
        </div>
    
      </div>
    </div>
    <script>
    var siteUrl = "https://thestrawh8.netlify.com/"
    $(document).ready(function() {
        $.when(
            $.getScript( siteUrl + "/assets/js/tipuesearch_set.js" ),
            $.getScript( siteUrl + "/assets/js/tipuesearch.js" ),
            $.Deferred(function( deferred ){
                $( deferred.resolve );
            })
        ).done(function() {
            $('#tipue_search_input').tipuesearch({
                'mode': 'json',
                'contentLocation': siteUrl + '/assets/js/tipuesearch_content.json'
            });
            $('#tipue_search_input').keyup(function (e) {
                if (e.keyCode == 13) {
                    $('#search-results').modal()
                }
            });
        });
    });
    </script><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5a66222e7a2540bb"></script><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5a66222e7a2540bb"></script><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5a66222e7a2540bb"></script>
</body>
</html>
